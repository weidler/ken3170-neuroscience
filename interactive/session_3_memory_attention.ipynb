{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Session 3: Memory, Attention, and Advanced Brain Models\n",
    "\n",
    "## Exploring Temporal Dynamics and Attention Mechanisms\n",
    "\n",
    "This final interactive session focuses on advanced neural mechanisms including memory systems, attention mechanisms, and their biological inspirations in the brain.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand recurrent neural networks and memory\n",
    "- Explore attention mechanisms and their brain connections\n",
    "- Interactive visualization of working memory dynamics\n",
    "- Compare different memory architectures (LSTM, GRU, Transformer attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸ§  Interactive Memory and Attention Systems ðŸ§ \")\n",
    "print(\"Exploring temporal dynamics and attention in neural networks...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 1: Working Memory Dynamics\n",
    "\n",
    "Explore how recurrent networks can maintain information over time, similar to working memory in the prefrontal cortex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \"\"\"Simple RNN for working memory demonstration\"\"\"\n",
    "    def __init__(self, input_size=1, hidden_size=10, output_size=1):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        return self.fc(output), hidden\n",
    "\n",
    "def create_working_memory_task(sequence_length=10, memory_delay=3, distraction_strength=0.5):\n",
    "    \"\"\"\n",
    "    Create a working memory task where the network needs to remember \n",
    "    an initial input through a delay period with distractions\n",
    "    \"\"\"\n",
    "    # Create sequence: [target, delay_period, distractors, recall_cue]\n",
    "    sequence = torch.zeros(1, sequence_length, 1)\n",
    "    target = torch.randn(1) * 0.8  # Target to remember\n",
    "    \n",
    "    # Set target at beginning\n",
    "    sequence[0, 0, 0] = target\n",
    "    \n",
    "    # Add distractors during delay period\n",
    "    for i in range(2, sequence_length - 1):\n",
    "        sequence[0, i, 0] = torch.randn(1) * distraction_strength\n",
    "    \n",
    "    # Recall cue at the end (special signal)\n",
    "    sequence[0, -1, 0] = 2.0  # Strong recall signal\n",
    "    \n",
    "    return sequence, target\n",
    "\n",
    "def simulate_working_memory(memory_delay=3, distraction_strength=0.5, \n",
    "                           hidden_size=10, show_hidden=True):\n",
    "    \"\"\"Simulate working memory task\"\"\"\n",
    "    \n",
    "    sequence_length = memory_delay + 5\n",
    "    model = SimpleRNN(hidden_size=hidden_size)\n",
    "    \n",
    "    # Create task\n",
    "    sequence, target = create_working_memory_task(sequence_length, memory_delay, distraction_strength)\n",
    "    \n",
    "    # Run through network\n",
    "    with torch.no_grad():\n",
    "        outputs, hidden_states = [], []\n",
    "        hidden = None\n",
    "        \n",
    "        for t in range(sequence_length):\n",
    "            input_t = sequence[:, t:t+1, :]\n",
    "            output, hidden = model(input_t, hidden)\n",
    "            outputs.append(output.squeeze().item())\n",
    "            hidden_states.append(hidden.squeeze().cpu().numpy())\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(3 if show_hidden else 2, 1, figsize=(12, 10 if show_hidden else 8))\n",
    "    \n",
    "    # Input sequence\n",
    "    inputs = sequence.squeeze().cpu().numpy()\n",
    "    axes[0].plot(inputs, 'bo-', linewidth=2, markersize=8, label='Input')\n",
    "    axes[0].axhline(y=target.item(), color='r', linestyle='--', alpha=0.7, label=f'Target: {target.item():.2f}')\n",
    "    axes[0].set_ylabel('Input Value')\n",
    "    axes[0].set_title('Working Memory Task: Input Sequence')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add annotations\n",
    "    axes[0].annotate('Target\\nPresentation', xy=(0, target.item()), \n",
    "                    xytext=(0.5, target.item() + 0.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                    fontsize=10, ha='center')\n",
    "    \n",
    "    axes[0].annotate('Delay +\\nDistractions', \n",
    "                    xy=(sequence_length//2, 0), xytext=(sequence_length//2, 1),\n",
    "                    arrowprops=dict(arrowstyle='->', color='orange'),\n",
    "                    fontsize=10, ha='center')\n",
    "    \n",
    "    axes[0].annotate('Recall\\nCue', xy=(sequence_length-1, 2), \n",
    "                    xytext=(sequence_length-1.5, 2.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='green'),\n",
    "                    fontsize=10, ha='center')\n",
    "    \n",
    "    # Network output\n",
    "    axes[1].plot(outputs, 'go-', linewidth=2, markersize=8, label='Network Output')\n",
    "    axes[1].axhline(y=target.item(), color='r', linestyle='--', alpha=0.7, label=f'Target: {target.item():.2f}')\n",
    "    axes[1].set_ylabel('Output Value')\n",
    "    axes[1].set_xlabel('Time Step')\n",
    "    axes[1].set_title('Network Response Over Time')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final recall accuracy\n",
    "    recall_error = abs(outputs[-1] - target.item())\n",
    "    axes[1].text(0.02, 0.98, f'Final Recall Error: {recall_error:.3f}', \n",
    "                transform=axes[1].transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    # Hidden state dynamics\n",
    "    if show_hidden:\n",
    "        hidden_array = np.array(hidden_states)\n",
    "        im = axes[2].imshow(hidden_array.T, aspect='auto', cmap='RdBu', \n",
    "                           interpolation='nearest')\n",
    "        axes[2].set_ylabel('Hidden Unit')\n",
    "        axes[2].set_xlabel('Time Step')\n",
    "        axes[2].set_title('Hidden State Dynamics (Working Memory Trace)')\n",
    "        plt.colorbar(im, ax=axes[2], label='Activation')\n",
    "        \n",
    "        # Highlight persistent activity\n",
    "        axes[2].axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Target Onset')\n",
    "        axes[2].axvline(x=sequence_length-1, color='green', linestyle='--', alpha=0.7, label='Recall Cue')\n",
    "        axes[2].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis\n",
    "    print(f\"ðŸ“Š Working Memory Analysis:\")\n",
    "    print(f\"Target value: {target.item():.3f}\")\n",
    "    print(f\"Final recall: {outputs[-1]:.3f}\")\n",
    "    print(f\"Memory accuracy: {100*(1-recall_error):.1f}%\")\n",
    "    \n",
    "    if recall_error < 0.1:\n",
    "        print(\"âœ… Excellent working memory performance!\")\n",
    "    elif recall_error < 0.3:\n",
    "        print(\"âš ï¸ Moderate working memory - some information retained\")\n",
    "    else:\n",
    "        print(\"âŒ Poor working memory - information largely lost\")\n",
    "\n",
    "# Create interactive widgets\n",
    "delay_widget = widgets.IntSlider(\n",
    "    value=3, min=1, max=8, step=1, description='Memory Delay:'\n",
    ")\n",
    "\n",
    "distraction_widget = widgets.FloatSlider(\n",
    "    value=0.5, min=0.0, max=2.0, step=0.1, description='Distraction:'\n",
    ")\n",
    "\n",
    "hidden_size_widget = widgets.IntSlider(\n",
    "    value=10, min=5, max=20, step=1, description='Hidden Size:'\n",
    ")\n",
    "\n",
    "show_hidden_widget = widgets.Checkbox(\n",
    "    value=True, description='Show Hidden States'\n",
    ")\n",
    "\n",
    "interactive_memory = widgets.interactive(\n",
    "    simulate_working_memory,\n",
    "    memory_delay=delay_widget,\n",
    "    distraction_strength=distraction_widget,\n",
    "    hidden_size=hidden_size_widget,\n",
    "    show_hidden=show_hidden_widget\n",
    ")\n",
    "\n",
    "display(interactive_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 2: Attention Visualization\n",
    "\n",
    "Explore how attention mechanisms work and their relationship to selective attention in the brain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_attention(query, keys, values, temperature=1.0):\n",
    "    \"\"\"Simple scaled dot-product attention\"\"\"\n",
    "    # Calculate attention scores\n",
    "    scores = torch.matmul(query, keys.transpose(-2, -1)) / np.sqrt(keys.size(-1))\n",
    "    scores = scores / temperature  # Temperature scaling\n",
    "    \n",
    "    # Softmax to get attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    # Apply attention to values\n",
    "    attended_output = torch.matmul(attention_weights, values)\n",
    "    \n",
    "    return attended_output, attention_weights\n",
    "\n",
    "def create_attention_scenario(scenario='spatial', sequence_length=8):\n",
    "    \"\"\"Create different attention scenarios\"\"\"\n",
    "    \n",
    "    if scenario == 'spatial':\n",
    "        # Spatial attention: focus on specific locations\n",
    "        positions = torch.linspace(0, 2*np.pi, sequence_length).unsqueeze(-1)\n",
    "        keys = torch.cat([torch.cos(positions), torch.sin(positions)], dim=-1)\n",
    "        values = torch.randn(sequence_length, 2) * 0.5 + keys\n",
    "        query = torch.tensor([[1.0, 0.0]])  # Look for rightward direction\n",
    "        labels = [f'Pos {i}' for i in range(sequence_length)]\n",
    "        \n",
    "    elif scenario == 'feature':\n",
    "        # Feature-based attention: focus on specific features\n",
    "        features = ['red', 'blue', 'green', 'yellow', 'big', 'small', 'round', 'square']\n",
    "        keys = torch.randn(sequence_length, 4)  # 4-dimensional feature space\n",
    "        values = torch.randn(sequence_length, 3)  # 3-dimensional output space\n",
    "        query = keys[2:3]  # Query for the 3rd item's features\n",
    "        labels = features[:sequence_length]\n",
    "        \n",
    "    else:  # temporal\n",
    "        # Temporal attention: focus on specific time points\n",
    "        time_stamps = torch.arange(sequence_length).float().unsqueeze(-1)\n",
    "        keys = torch.cat([time_stamps, torch.sin(time_stamps), torch.cos(time_stamps)], dim=-1)\n",
    "        values = torch.randn(sequence_length, 2)\n",
    "        query = torch.tensor([[sequence_length//2, 0.0, 1.0]])  # Mid-time query\n",
    "        labels = [f'T{i}' for i in range(sequence_length)]\n",
    "    \n",
    "    return query, keys, values, labels\n",
    "\n",
    "def visualize_attention(scenario='spatial', temperature=1.0, query_strength=1.0):\n",
    "    \"\"\"Visualize attention mechanisms\"\"\"\n",
    "    \n",
    "    sequence_length = 8\n",
    "    query, keys, values, labels = create_attention_scenario(scenario, sequence_length)\n",
    "    \n",
    "    # Scale query by strength\n",
    "    query = query * query_strength\n",
    "    \n",
    "    # Apply attention\n",
    "    attended_output, attention_weights = simple_attention(query, keys, values, temperature)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Attention weights visualization\n",
    "    weights = attention_weights.squeeze().detach().numpy()\n",
    "    bars = axes[0, 0].bar(range(sequence_length), weights, alpha=0.7, \n",
    "                          color=plt.cm.viridis(weights / weights.max()))\n",
    "    axes[0, 0].set_xlabel('Sequence Position')\n",
    "    axes[0, 0].set_ylabel('Attention Weight')\n",
    "    axes[0, 0].set_title('Attention Weights Distribution')\n",
    "    axes[0, 0].set_xticks(range(sequence_length))\n",
    "    axes[0, 0].set_xticklabels(labels, rotation=45)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value annotations\n",
    "    for i, (bar, weight) in enumerate(zip(bars, weights)):\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                       f'{weight:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 2. Query-Key similarity matrix\n",
    "    query_expanded = query.expand(sequence_length, -1)\n",
    "    similarities = F.cosine_similarity(query_expanded, keys, dim=-1).detach().numpy()\n",
    "    \n",
    "    axes[0, 1].bar(range(sequence_length), similarities, alpha=0.7, color='orange')\n",
    "    axes[0, 1].set_xlabel('Sequence Position')\n",
    "    axes[0, 1].set_ylabel('Query-Key Similarity')\n",
    "    axes[0, 1].set_title('Query-Key Similarity Scores')\n",
    "    axes[0, 1].set_xticks(range(sequence_length))\n",
    "    axes[0, 1].set_xticklabels(labels, rotation=45)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Key and Value representations (for spatial scenario)\n",
    "    if scenario == 'spatial':\n",
    "        keys_np = keys.detach().numpy()\n",
    "        scatter = axes[1, 0].scatter(keys_np[:, 0], keys_np[:, 1], \n",
    "                                    s=weights*500, c=weights, cmap='viridis', alpha=0.7)\n",
    "        axes[1, 0].scatter(query[0, 0], query[0, 1], s=100, c='red', marker='*', label='Query')\n",
    "        \n",
    "        for i, (x, y, label) in enumerate(zip(keys_np[:, 0], keys_np[:, 1], labels)):\n",
    "            axes[1, 0].annotate(label, (x, y), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        axes[1, 0].set_xlabel('Key Dimension 1')\n",
    "        axes[1, 0].set_ylabel('Key Dimension 2')\n",
    "        axes[1, 0].set_title('Spatial Attention in Key Space\\n(Size âˆ Attention Weight)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        plt.colorbar(scatter, ax=axes[1, 0], label='Attention Weight')\n",
    "    else:\n",
    "        # For non-spatial scenarios, show key-value relationship\n",
    "        axes[1, 0].imshow(keys.T.detach().numpy(), aspect='auto', cmap='coolwarm')\n",
    "        axes[1, 0].set_xlabel('Sequence Position')\n",
    "        axes[1, 0].set_ylabel('Key Dimension')\n",
    "        axes[1, 0].set_title('Key Representations')\n",
    "        axes[1, 0].set_xticks(range(sequence_length))\n",
    "        axes[1, 0].set_xticklabels(labels, rotation=45)\n",
    "    \n",
    "    # 4. Attended output\n",
    "    values_np = values.detach().numpy()\n",
    "    attended_np = attended_output.squeeze().detach().numpy()\n",
    "    \n",
    "    # Show original values and attended result\n",
    "    axes[1, 1].plot(values_np.T, alpha=0.3, label=['Value Dim 1', 'Value Dim 2', 'Value Dim 3'][:values_np.shape[1]])\n",
    "    axes[1, 1].scatter(range(len(attended_np)), attended_np, color='red', s=100, \n",
    "                      label='Attended Output', zorder=5)\n",
    "    axes[1, 1].set_xlabel('Output Dimension')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].set_title('Values and Attended Output')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analysis\n",
    "    max_attention_idx = np.argmax(weights)\n",
    "    max_attention_weight = weights[max_attention_idx]\n",
    "    attention_entropy = -np.sum(weights * np.log(weights + 1e-8))  # Attention entropy\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Attention Analysis ({scenario} attention):\")\n",
    "    print(f\"Most attended position: {labels[max_attention_idx]} (weight: {max_attention_weight:.3f})\")\n",
    "    print(f\"Attention entropy: {attention_entropy:.3f} (lower = more focused)\")\n",
    "    print(f\"Temperature effect: {temperature:.1f} (lower = sharper attention)\")\n",
    "    \n",
    "    if attention_entropy < 1.0:\n",
    "        print(\"ðŸ” Sharp, focused attention\")\n",
    "    elif attention_entropy < 2.0:\n",
    "        print(\"ðŸ‘€ Moderate attention spread\")\n",
    "    else:\n",
    "        print(\"ðŸŒ Diffuse, distributed attention\")\n",
    "\n",
    "# Create interactive widgets\n",
    "scenario_widget = widgets.Dropdown(\n",
    "    options=['spatial', 'feature', 'temporal'],\n",
    "    value='spatial',\n",
    "    description='Attention Type:'\n",
    ")\n",
    "\n",
    "temperature_widget = widgets.FloatSlider(\n",
    "    value=1.0, min=0.1, max=3.0, step=0.1, description='Temperature:'\n",
    ")\n",
    "\n",
    "query_strength_widget = widgets.FloatSlider(\n",
    "    value=1.0, min=0.1, max=3.0, step=0.1, description='Query Strength:'\n",
    ")\n",
    "\n",
    "interactive_attention = widgets.interactive(\n",
    "    visualize_attention,\n",
    "    scenario=scenario_widget,\n",
    "    temperature=temperature_widget,\n",
    "    query_strength=query_strength_widget\n",
    ")\n",
    "\n",
    "display(interactive_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological Connections and Brain Systems\n",
    "\n",
    "### Working Memory and the Prefrontal Cortex\n",
    "- **Persistent Activity**: The hidden state dynamics you observed mirror the persistent neural firing in PFC during working memory tasks\n",
    "- **Distraction Resistance**: The ability to maintain information despite distractors relates to cognitive control mechanisms\n",
    "- **Delay Period Activity**: Neural activity during memory delays shows similar patterns to our RNN hidden states\n",
    "\n",
    "### Attention Systems in the Brain\n",
    "- **Spatial Attention**: Parietal cortex mechanisms for attending to locations in space\n",
    "- **Feature Attention**: Temporal cortex systems for attending to specific object features\n",
    "- **Temporal Attention**: Frontal systems for attending to specific time points\n",
    "\n",
    "### Key Parallels\n",
    "1. **Selective Enhancement**: Both artificial and biological attention enhance relevant information\n",
    "2. **Competition**: Limited processing resources lead to competitive dynamics\n",
    "3. **Top-down Control**: Query-driven attention mirrors goal-directed attention control\n",
    "4. **Dynamic Allocation**: Attention weights change based on task demands\n",
    "\n",
    "## Final Reflection Questions\n",
    "\n",
    "1. **Memory vs Attention**: How do working memory and attention mechanisms complement each other in cognitive processing?\n",
    "\n",
    "2. **Biological Plausibility**: Which aspects of these artificial systems seem most/least biologically plausible?\n",
    "\n",
    "3. **Computational Efficiency**: How do attention mechanisms help with the computational limitations of processing all information equally?\n",
    "\n",
    "4. **Future Directions**: What other brain functions could be modeled using similar neural network principles?\n",
    "\n",
    "## Course Wrap-up\n",
    "\n",
    "Congratulations! You've now explored:\n",
    "- Basic neural computation principles\n",
    "- Hierarchical processing in deep networks\n",
    "- Memory systems and temporal dynamics\n",
    "- Attention mechanisms and selective processing\n",
    "\n",
    "These foundational concepts form the basis for understanding how artificial neural networks can model brain function and contribute to both neuroscience understanding and AI development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"
  },\n",
   "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.8.0"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n}