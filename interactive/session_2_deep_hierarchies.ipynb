{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Session 2: Deep Networks and Brain Hierarchies\n",
    "\n",
    "## Exploring Hierarchical Processing\n",
    "\n",
    "This session focuses on understanding how deep neural networks can model the hierarchical processing found in brain systems, particularly in vision and language processing.\n",
    "\n",
    "### Learning Goals\n",
    "- Understand hierarchical feature learning\n",
    "- Explore convolutional neural networks and visual processing\n",
    "- Interactive visualization of feature maps and filters\n",
    "- Compare artificial and biological hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import seaborn as sns\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üß† Interactive Deep Learning for Brain Modeling üß†\")\n",
    "print(\"Exploring hierarchical processing in neural networks...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 1: Convolutional Filters and Edge Detection\n",
    "\n",
    "Explore how convolutional filters work, inspired by simple cells in the visual cortex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_image(image_type='checkerboard', size=64):\n",
    "    \"\"\"Create different test images\"\"\"\n",
    "    if image_type == 'checkerboard':\n",
    "        img = np.zeros((size, size))\n",
    "        for i in range(0, size, 8):\n",
    "            for j in range(0, size, 8):\n",
    "                if (i//8 + j//8) % 2 == 0:\n",
    "                    img[i:i+8, j:j+8] = 1\n",
    "    elif image_type == 'circles':\n",
    "        img = np.zeros((size, size))\n",
    "        center = size // 2\n",
    "        y, x = np.ogrid[:size, :size]\n",
    "        mask1 = (x - center)**2 + (y - center)**2 <= (size//4)**2\n",
    "        mask2 = (x - center)**2 + (y - center)**2 <= (size//6)**2\n",
    "        img[mask1] = 1\n",
    "        img[mask2] = 0\n",
    "    elif image_type == 'stripes':\n",
    "        img = np.zeros((size, size))\n",
    "        for i in range(0, size, 8):\n",
    "            img[i:i+4, :] = 1\n",
    "    else:  # random\n",
    "        img = np.random.rand(size, size)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def apply_conv_filter(image, filter_type='horizontal_edge', custom_filter=None):\n",
    "    \"\"\"Apply different convolutional filters\"\"\"\n",
    "    \n",
    "    # Define different filters inspired by visual cortex\n",
    "    filters = {\n",
    "        'horizontal_edge': np.array([[-1, -1, -1], [2, 2, 2], [-1, -1, -1]]),\n",
    "        'vertical_edge': np.array([[-1, 2, -1], [-1, 2, -1], [-1, 2, -1]]),\n",
    "        'diagonal_edge': np.array([[0, -1, -1], [1, 0, -1], [1, 1, 0]]),\n",
    "        'gaussian_blur': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,\n",
    "        'sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
    "        'laplacian': np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "    }\n",
    "    \n",
    "    if custom_filter is not None:\n",
    "        kernel = custom_filter\n",
    "    else:\n",
    "        kernel = filters[filter_type]\n",
    "    \n",
    "    # Apply convolution\n",
    "    filtered = cv2.filter2D(image, -1, kernel)\n",
    "    \n",
    "    return filtered, kernel\n",
    "\n",
    "def interactive_convolution(image_type='checkerboard', filter_type='horizontal_edge', \n",
    "                           show_kernel=True):\n",
    "    \"\"\"Interactive convolution demonstration\"\"\"\n",
    "    \n",
    "    # Create image\n",
    "    img = create_sample_image(image_type)\n",
    "    \n",
    "    # Apply filter\n",
    "    filtered_img, kernel = apply_conv_filter(img, filter_type)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3 if show_kernel else 2, figsize=(15 if show_kernel else 10, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Filtered image\n",
    "    axes[1].imshow(filtered_img, cmap='gray')\n",
    "    axes[1].set_title(f'After {filter_type.replace(\"_\", \" \").title()} Filter')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Kernel visualization\n",
    "    if show_kernel:\n",
    "        im = axes[2].imshow(kernel, cmap='RdBu', vmin=-2, vmax=2)\n",
    "        axes[2].set_title('Filter Kernel')\n",
    "        \n",
    "        # Add text annotations for kernel values\n",
    "        for i in range(kernel.shape[0]):\n",
    "            for j in range(kernel.shape[1]):\n",
    "                text = axes[2].text(j, i, f'{kernel[i, j]:.1f}',\n",
    "                                  ha=\"center\", va=\"center\", color=\"white\" if abs(kernel[i, j]) > 1 else \"black\")\n",
    "        \n",
    "        plt.colorbar(im, ax=axes[2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Explanation\n",
    "    explanations = {\n",
    "        'horizontal_edge': \"Detects horizontal edges - similar to simple cells in V1 that respond to specific orientations\",\n",
    "        'vertical_edge': \"Detects vertical edges - models orientation-selective neurons in visual cortex\",\n",
    "        'diagonal_edge': \"Detects diagonal edges - shows how different orientations can be detected\",\n",
    "        'gaussian_blur': \"Smooths the image - similar to center-surround receptive fields\",\n",
    "        'sharpen': \"Enhances edges and details - amplifies high-frequency components\",\n",
    "        'laplacian': \"Edge detection filter - responds to rapid intensity changes\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üîç {explanations.get(filter_type, 'Custom filter applied')}\")\n",
    "\n",
    "# Create interactive widgets\n",
    "image_widget = widgets.Dropdown(\n",
    "    options=['checkerboard', 'circles', 'stripes', 'random'],\n",
    "    value='checkerboard',\n",
    "    description='Image Type:'\n",
    ")\n",
    "\n",
    "filter_widget = widgets.Dropdown(\n",
    "    options=['horizontal_edge', 'vertical_edge', 'diagonal_edge', 'gaussian_blur', 'sharpen', 'laplacian'],\n",
    "    value='horizontal_edge',\n",
    "    description='Filter:'\n",
    ")\n",
    "\n",
    "kernel_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Show Kernel'\n",
    ")\n",
    "\n",
    "interactive_conv = widgets.interactive(\n",
    "    interactive_convolution,\n",
    "    image_type=image_widget,\n",
    "    filter_type=filter_widget,\n",
    "    show_kernel=kernel_widget\n",
    ")\n",
    "\n",
    "display(interactive_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 2: Feature Map Visualization\n",
    "\n",
    "Explore how features become more complex as we go deeper into the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"A simple CNN for feature visualization\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x, return_features=False):\n",
    "        features = []\n",
    "        \n",
    "        # First layer\n",
    "        x1 = torch.relu(self.conv1(x))\n",
    "        features.append(x1)\n",
    "        \n",
    "        # Second layer\n",
    "        x2 = torch.relu(self.conv2(x1))\n",
    "        features.append(x2)\n",
    "        \n",
    "        # Third layer\n",
    "        x3 = torch.relu(self.conv3(x2))\n",
    "        features.append(x3)\n",
    "        \n",
    "        if return_features:\n",
    "            return features\n",
    "        return x3\n",
    "\n",
    "def visualize_feature_maps(layer_num=1, feature_map=0, input_type='checkerboard'):\n",
    "    \"\"\"Visualize feature maps from different layers\"\"\"\n",
    "    \n",
    "    # Create model and input\n",
    "    model = SimpleCNN()\n",
    "    model.eval()\n",
    "    \n",
    "    # Create input image\n",
    "    img = create_sample_image(input_type, 64)\n",
    "    input_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "    \n",
    "    # Get feature maps\n",
    "    with torch.no_grad():\n",
    "        features = model(input_tensor, return_features=True)\n",
    "    \n",
    "    # Select layer and feature map\n",
    "    selected_features = features[layer_num - 1]\n",
    "    num_features = selected_features.shape[1]\n",
    "    feature_map = min(feature_map, num_features - 1)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title('Input Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Selected feature map\n",
    "    feature_data = selected_features[0, feature_map].cpu().numpy()\n",
    "    axes[1].imshow(feature_data, cmap='viridis')\n",
    "    axes[1].set_title(f'Layer {layer_num}, Feature Map {feature_map}')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # All feature maps from selected layer (grid)\n",
    "    if num_features <= 16:\n",
    "        grid_size = int(np.ceil(np.sqrt(num_features)))\n",
    "        feature_grid = np.zeros((grid_size * feature_data.shape[0], grid_size * feature_data.shape[1]))\n",
    "        \n",
    "        for i in range(num_features):\n",
    "            row = i // grid_size\n",
    "            col = i % grid_size\n",
    "            start_row = row * feature_data.shape[0]\n",
    "            end_row = start_row + feature_data.shape[0]\n",
    "            start_col = col * feature_data.shape[1]\n",
    "            end_col = start_col + feature_data.shape[1]\n",
    "            \n",
    "            feature_grid[start_row:end_row, start_col:end_col] = selected_features[0, i].cpu().numpy()\n",
    "        \n",
    "        axes[2].imshow(feature_grid, cmap='viridis')\n",
    "        axes[2].set_title(f'All {num_features} Feature Maps (Layer {layer_num})')\n",
    "    else:\n",
    "        # Show mean activation if too many features\n",
    "        mean_activation = torch.mean(selected_features[0], dim=0).cpu().numpy()\n",
    "        axes[2].imshow(mean_activation, cmap='viridis')\n",
    "        axes[2].set_title(f'Mean Activation (Layer {layer_num})')\n",
    "    \n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Information about the layer\n",
    "    layer_info = {\n",
    "        1: \"Layer 1: Detects simple features like edges and basic patterns\",\n",
    "        2: \"Layer 2: Combines simple features into more complex patterns\", \n",
    "        3: \"Layer 3: Creates high-level feature representations\"\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä {layer_info.get(layer_num, 'Feature visualization')}\")\n",
    "    print(f\"Number of feature maps in this layer: {num_features}\")\n",
    "    print(f\"Feature map size: {feature_data.shape}\")\n",
    "\n",
    "# Create interactive widgets\n",
    "layer_widget = widgets.IntSlider(\n",
    "    value=1, min=1, max=3, step=1, description='Layer:'\n",
    ")\n",
    "\n",
    "feature_widget = widgets.IntSlider(\n",
    "    value=0, min=0, max=31, step=1, description='Feature Map:'\n",
    ")\n",
    "\n",
    "input_widget = widgets.Dropdown(\n",
    "    options=['checkerboard', 'circles', 'stripes', 'random'],\n",
    "    value='checkerboard',\n",
    "    description='Input:'\n",
    ")\n",
    "\n",
    "interactive_features = widgets.interactive(\n",
    "    visualize_feature_maps,\n",
    "    layer_num=layer_widget,\n",
    "    feature_map=feature_widget,\n",
    "    input_type=input_widget\n",
    ")\n",
    "\n",
    "display(interactive_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological Connections\n",
    "\n",
    "### Visual Cortex Hierarchy\n",
    "The visual cortex processes information in a hierarchical manner:\n",
    "\n",
    "1. **V1 (Primary Visual Cortex)**: Simple and complex cells detect edges, orientations\n",
    "2. **V2**: Combines V1 features into more complex patterns\n",
    "3. **V4**: Color and shape processing\n",
    "4. **IT (Inferotemporal Cortex)**: Object recognition\n",
    "\n",
    "Our CNN layers mirror this hierarchy:\n",
    "- **Layer 1**: Edge detection (like V1 simple cells)\n",
    "- **Layer 2**: Pattern combination (like V2)\n",
    "- **Layer 3**: Complex feature detection (like V4/IT)\n",
    "\n",
    "### Discussion Questions\n",
    "\n",
    "1. **Feature Complexity**: How do the features change as you go from layer 1 to layer 3?\n",
    "\n",
    "2. **Receptive Fields**: Notice how deeper layers respond to larger portions of the input. How does this relate to receptive field sizes in the brain?\n",
    "\n",
    "3. **Specialization**: Different feature maps in the same layer detect different patterns. How might this relate to neural specialization in the brain?\n",
    "\n",
    "4. **Hierarchical Processing**: Can you see how simple features combine to create complex ones? How might this apply to other brain functions beyond vision?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}