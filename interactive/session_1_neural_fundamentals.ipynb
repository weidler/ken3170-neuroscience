{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Session 1: Exploring Neural Network Fundamentals\n",
    "\n",
    "## Welcome to Interactive Brain Modeling!\n",
    "\n",
    "This interactive session will guide you through the fundamental concepts of neural networks and their relationship to brain function. You'll experiment with different parameters and see their effects in real-time.\n",
    "\n",
    "### Session Overview\n",
    "- Interactive visualization of single neurons\n",
    "- Parameter exploration with sliders and widgets\n",
    "- Real-time plotting of activation functions\n",
    "- Hands-on exploration of learning dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ§  Welcome to Interactive Brain Modeling! ðŸ§ \")\n",
    "print(\"Let's explore how artificial neurons work...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 1: Neuron Activation Functions\n",
    "\n",
    "Use the sliders below to explore different activation functions and their parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_function(func_type='sigmoid', steepness=1.0, threshold=0.0):\n",
    "    \"\"\"Interactive plot of activation functions\"\"\"\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    \n",
    "    if func_type == 'sigmoid':\n",
    "        y = 1 / (1 + np.exp(-steepness * (x - threshold)))\n",
    "        title = f'Sigmoid Function (steepness={steepness:.1f}, threshold={threshold:.1f})'\n",
    "    elif func_type == 'tanh':\n",
    "        y = np.tanh(steepness * (x - threshold))\n",
    "        title = f'Tanh Function (steepness={steepness:.1f}, threshold={threshold:.1f})'\n",
    "    elif func_type == 'relu':\n",
    "        y = np.maximum(0, steepness * (x - threshold))\n",
    "        title = f'ReLU Function (slope={steepness:.1f}, threshold={threshold:.1f})'\n",
    "    else:  # step function\n",
    "        y = np.where(x > threshold, 1, 0)\n",
    "        title = f'Step Function (threshold={threshold:.1f})'\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, linewidth=3, label=func_type.capitalize())\n",
    "    plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "    plt.xlabel('Input (x)', fontsize=12)\n",
    "    plt.ylabel('Output (activation)', fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widgets\n",
    "function_widget = widgets.Dropdown(\n",
    "    options=['sigmoid', 'tanh', 'relu', 'step'],\n",
    "    value='sigmoid',\n",
    "    description='Function:'\n",
    ")\n",
    "\n",
    "steepness_widget = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.1,\n",
    "    max=5.0,\n",
    "    step=0.1,\n",
    "    description='Steepness:'\n",
    ")\n",
    "\n",
    "threshold_widget = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Threshold:'\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "interactive_plot = widgets.interactive(\n",
    "    plot_activation_function,\n",
    "    func_type=function_widget,\n",
    "    steepness=steepness_widget,\n",
    "    threshold=threshold_widget\n",
    ")\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Element 2: Simple Perceptron Decision Boundary\n",
    "\n",
    "Watch how a perceptron learns to classify data points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_perceptron_learning(learning_rate=0.1, num_points=50, noise_level=0.1):\n",
    "    \"\"\"Interactive visualization of perceptron learning\"\"\"\n",
    "    \n",
    "    # Generate random data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(num_points, 2)\n",
    "    # Create linearly separable data with some noise\n",
    "    y = (X[:, 0] + X[:, 1] > 0).astype(int) * 2 - 1  # -1 or 1\n",
    "    \n",
    "    # Add noise\n",
    "    noise_indices = np.random.choice(len(y), int(noise_level * len(y)), replace=False)\n",
    "    y[noise_indices] *= -1\n",
    "    \n",
    "    # Simple perceptron learning\n",
    "    weights = np.random.randn(3) * 0.1  # Including bias\n",
    "    X_with_bias = np.column_stack([np.ones(len(X)), X])\n",
    "    \n",
    "    # Plot initial state\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot data points\n",
    "    colors = ['red' if label == -1 else 'blue' for label in y]\n",
    "    ax1.scatter(X[:, 0], X[:, 1], c=colors, s=50, alpha=0.7)\n",
    "    ax1.set_xlabel('Feature 1')\n",
    "    ax1.set_ylabel('Feature 2')\n",
    "    ax1.set_title('Perceptron Classification (Initial)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot decision boundary (initial)\n",
    "    if weights[1] != 0:  # Avoid division by zero\n",
    "        x_line = np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100)\n",
    "        y_line = -(weights[0] + weights[1] * x_line) / weights[2]\n",
    "        ax1.plot(x_line, y_line, 'k--', linewidth=2, label='Initial Decision Boundary')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim(X[:, 0].min()-1, X[:, 0].max()+1)\n",
    "    ax1.set_ylim(X[:, 1].min()-1, X[:, 1].max()+1)\n",
    "    \n",
    "    # Learning process\n",
    "    errors = []\n",
    "    for epoch in range(100):\n",
    "        epoch_errors = 0\n",
    "        for i in range(len(X)):\n",
    "            prediction = np.sign(np.dot(X_with_bias[i], weights))\n",
    "            if prediction != y[i]:\n",
    "                weights += learning_rate * y[i] * X_with_bias[i]\n",
    "                epoch_errors += 1\n",
    "        errors.append(epoch_errors)\n",
    "        if epoch_errors == 0:\n",
    "            break\n",
    "    \n",
    "    # Plot final decision boundary\n",
    "    if weights[1] != 0:\n",
    "        x_line = np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100)\n",
    "        y_line = -(weights[0] + weights[1] * x_line) / weights[2]\n",
    "        ax1.plot(x_line, y_line, 'g-', linewidth=3, label='Final Decision Boundary')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot learning curve\n",
    "    ax2.plot(errors, 'o-', linewidth=2, markersize=4)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Number of Errors')\n",
    "    ax2.set_title('Learning Progress')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ… Converged after {len(errors)} epochs!\")\n",
    "    print(f\"Final weights: {weights}\")\n",
    "\n",
    "# Create interactive controls\n",
    "lr_widget = widgets.FloatSlider(value=0.1, min=0.01, max=1.0, step=0.01, description='Learning Rate:')\n",
    "points_widget = widgets.IntSlider(value=50, min=20, max=200, step=10, description='Num Points:')\n",
    "noise_widget = widgets.FloatSlider(value=0.1, min=0.0, max=0.5, step=0.05, description='Noise Level:')\n",
    "\n",
    "interactive_perceptron = widgets.interactive(\n",
    "    interactive_perceptron_learning,\n",
    "    learning_rate=lr_widget,\n",
    "    num_points=points_widget,\n",
    "    noise_level=noise_widget\n",
    ")\n",
    "\n",
    "display(interactive_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "After exploring the interactive elements above, consider these questions:\n",
    "\n",
    "1. **Activation Functions**: How do different activation functions relate to the \"all-or-nothing\" firing behavior of biological neurons?\n",
    "\n",
    "2. **Learning Dynamics**: What happens when you increase the learning rate? Why might very high learning rates be problematic?\n",
    "\n",
    "3. **Noise and Robustness**: How does the perceptron handle noisy data? What does this tell us about the robustness of simple neural models?\n",
    "\n",
    "4. **Biological Inspiration**: Which aspects of these artificial neurons seem most similar to biological neurons? Which aspects are clearly different?\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next interactive session, we'll explore more complex architectures and their biological inspirations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}